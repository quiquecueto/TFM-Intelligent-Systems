{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook TFM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './Hangzhou-mobility-data-set'\n",
    "archivos_csv = [archivo for archivo in os.listdir(dir) if archivo.startswith('record') and archivo.endswith('.csv')]\n",
    "dataframes = [pd.read_csv(os.path.join(dir, archivo)) for archivo in archivos_csv]\n",
    "records = pd.concat(dataframes, ignore_index=True)\n",
    "est = pd.read_csv('./Hangzhou-mobility-data-set/Metro_roadMap.csv')\n",
    "meteo = pd.read_csv('./Hangzhou-mobility-data-set/HangzhouMeteoData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['time'] = pd.to_datetime(records['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lala = meteo[(meteo['icon'].notna()) & meteo['icon']!=0]\n",
    "lala['icon']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de nulos y tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_de_ceros = (meteo['precip'] == 0).sum()\n",
    "cantidad_de_ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores nulos en los records\n",
    "\n",
    "hay_nan = records.isna().any().any()\n",
    "if hay_nan:\n",
    "    print(\"El DataFrame contiene valores NaN.\")\n",
    "else:\n",
    "    print(\"El DataFrame no contiene valores NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores nulos en las estaciones\n",
    "hay_nan = est.isna().any().any()\n",
    "if hay_nan:\n",
    "    print(\"El DataFrame contiene valores NaN.\")\n",
    "else:\n",
    "    print(\"El DataFrame no contiene valores NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores nulos en las estaciones\n",
    "hay_nan = meteo.isna().any().any()\n",
    "if hay_nan:\n",
    "    print(\"El DataFrame contiene valores NaN.\")\n",
    "else:\n",
    "    print(\"El DataFrame no contiene valores NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las columnas con valores nulos\n",
    "columnas_con_nulos = meteo.columns[meteo.isnull().any()]\n",
    "\n",
    "# Mostrar las columnas con valores nulos y la cantidad de valores nulos en cada una\n",
    "for columna in columnas_con_nulos:\n",
    "    cantidad_nulos = meteo[columna].isnull().sum()\n",
    "    print(f'Columna \"{columna}\" tiene {cantidad_nulos} valores nulos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horas no completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tienes un DataFrame llamado records\n",
    "# Crea un DataFrame con las columnas 'time', 'stationID' y 'day'\n",
    "df_time_station_day = records[['time', 'stationID']]\n",
    "df_time_station_day['day'] = df_time_station_day['time'].dt.date\n",
    "\n",
    "# Extrae la hora de la columna 'time'\n",
    "df_time_station_day['hour'] = df_time_station_day['time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por día, hora y estación y cuenta las observaciones en cada grupo\n",
    "daily_hourly_station_counts = df_time_station_day.groupby(['day', 'hour', 'stationID']).size().reset_index(name='count')\n",
    "daily_hourly_station_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la lista de todas las estaciones únicas\n",
    "estaciones_unicas = df_time_station_day['stationID'].unique()\n",
    "estaciones_unicas.sort()\n",
    "estaciones_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.arange(24)\n",
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_hourly_station_counts[(daily_hourly_station_counts['stationID'] == 4) & (daily_hourly_station_counts['hour'] == 16)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hour in range(24):\n",
    "hours_to_delete = []\n",
    "est_and_hour = []\n",
    "for hour in hours:\n",
    "    for est in estaciones_unicas:\n",
    "        if (daily_hourly_station_counts[(daily_hourly_station_counts['stationID'] == est) & (daily_hourly_station_counts['hour'] == hour)].count().iloc[0] != 25):# & hora not in hours_to_delete:\n",
    "            hours_to_delete.append(hour)\n",
    "            est_and_hour.append([est,hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(est_and_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_to_delete.sort()\n",
    "unique_values = list(set(hours_to_delete))\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = records.loc[~records['time'].dt.hour.isin(unique_values)]\n",
    "records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time').drop(columns=['payType']).groupby([pd.Grouper(freq='H', level=0),'stationID', 'lineID','status'])['userID'].agg('count').reset_index()\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un diccionario de mapeo de valores únicos en \"lineID\" a números\n",
    "mapeo_lineID = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    # Agrega más mapeos según sea necesario\n",
    "}\n",
    "\n",
    "# Aplicar la conversión utilizando el método map\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].map(mapeo_lineID)\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].astype('category')\n",
    "df_agrupado.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.corr()['userID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = df_agrupado[(df_agrupado['stationID']==10) & (df_agrupado['time'].dt.day==20)]\n",
    "test_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por la columna 'stationID' y contar los valores únicos en 'lineID'\n",
    "stations_with_different_lines = df_agrupado.groupby('stationID')['lineID'].nunique()\n",
    "\n",
    "# Filtrar las estaciones que tienen más de un valor único en 'lineID'\n",
    "stations_with_multiple_lines = stations_with_different_lines[stations_with_different_lines > 1]\n",
    "stations_with_multiple_lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby(['stationID', df_agrupado.index.date, 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.reset_index(inplace=True)\n",
    "df_agrupado.rename(columns={\"level_1\": 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_estacion  = df_agrupado[df_agrupado['stationID'] == 15]\n",
    "filas_estacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['entrada'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excepciones_entrada = df_agrupado[df_agrupado['entrada']>200000]\n",
    "excepciones_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['salida'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excepciones_entrada = df_agrupado[df_agrupado['salida']>150000]\n",
    "excepciones_entrada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupaciones varias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby([pd.Grouper(freq='H', level=0),'stationID', 'lineID','payType','status'])['userID'].agg('count').reset_index()\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df_agrupado.groupby(['stationID', df_agrupado.index.date, 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''records.set_index('time', inplace=True)\n",
    "df_agrupado = records.set_index('time').groupby('stationID')\n",
    "for estacion, datos in df_agrupado:\n",
    "    print(f\"Estación {estacion}:\")\n",
    "    print(datos)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''resultados = pd.DataFrame()\n",
    "for estacion, datos in df_agrupado:\n",
    "    recuento_usuarios = datos['userID'].resample('10T').count()\n",
    "    # Agregar los resultados al DataFrame de resultados\n",
    "    resultados[f'Estacion_{estacion}'] = recuento_usuarios\n",
    "\n",
    "resultados'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.reset_index(inplace=True)\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_in_out = records.groupby(['stationID', records.index.date, records.index.hour, 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby(['stationID', df_agrupado.index, 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time').drop(columns=['payType']).groupby([pd.Grouper(freq='H', level=0),'stationID', 'lineID','status'])['userID'].agg('count').reset_index()\n",
    "# Definir un diccionario de mapeo de valores únicos en \"lineID\" a números\n",
    "mapeo_lineID = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    # Agrega más mapeos según sea necesario\n",
    "}\n",
    "\n",
    "# Aplicar la conversión utilizando el método map\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].map(mapeo_lineID)\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].astype('category')\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "#Para agrupar por horas poner 'H' en la frecuencia del Grouper\n",
    "df_agrupado = df_agrupado.groupby(['stationID', pd.Grouper(freq='10T', level=0),'lineID' ,'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado.reset_index(inplace=True)\n",
    "mapeo_lineID = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    # Agrega más mapeos según sea necesario\n",
    "}\n",
    "\n",
    "# Aplicar la conversión utilizando el método map\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].map(mapeo_lineID)\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = df_agrupado[(df_agrupado['time'].dt.day==20)]\n",
    "test_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones con dataset METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.rename(columns={\"datetime\": 'time'}, inplace=True)\n",
    "meteo['time'] = pd.to_datetime(meteo['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Contar valores diferentes de 0 en la columna\n",
    "condicion_1 = (meteo['precip'] != 0.0).sum()\n",
    "\n",
    "# Contar valores diferentes de NaN en la columna\n",
    "condicion_2 = (~meteo['severerisk'].isna()).sum()\n",
    "\n",
    "# Contar valores iguales a un valor de cadena concreto en la columna\n",
    "valor_concreto = 'Partially cloudy'\n",
    "condicion_3 = (meteo['conditions'] == valor_concreto).sum()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Valores diferentes de 0: {condicion_1}')\n",
    "print(f'Valores diferentes de NaN: {condicion_2}')\n",
    "print(f'Valores iguales a \"{valor_concreto}\": {condicion_3}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = meteo.loc[~meteo['time'].dt.hour.isin(unique_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borramos variables irrelevantes o con \n",
    "#meteodrop = meteo.drop(['icon','conditions','name','severerisk','stations','snow', 'snowdepth', 'windgust','dew','preciptype'], axis=1)\n",
    "\n",
    "meteodrop = meteo[['time','temp','humidity','windspeed']]\n",
    "meteodrop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe agrupado por horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby(['stationID', pd.Grouper(freq='H', level=0), 'lineID', 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado.reset_index(inplace=True)\n",
    "mapeo_lineID = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    # Agrega más mapeos según sea necesario\n",
    "}\n",
    "\n",
    "# Aplicar la conversión utilizando el método map\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].map(mapeo_lineID)\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].astype('category')\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = df_agrupado.merge(meteodrop, on=['time'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado[(resultado['stationID'] == 1) & (resultado['time'].dt.day == 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado[(resultado['stationID']==10) & (resultado['time'].dt.day==20)].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora = resultado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['year'] = resultado['time'].dt.year\n",
    "resultado['month'] = resultado['time'].dt.month\n",
    "resultado['day'] = resultado['time'].dt.day\n",
    "resultado['hour'] = resultado['time'].dt.hour\n",
    "resultado.drop(columns=['time'], inplace=True)\n",
    "resultado_hora = resultado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = resultado_fecha_junta_hora[(resultado_fecha_junta_hora['stationID']==10) & (resultado_fecha_junta_hora['time'].dt.day==20)]\n",
    "test_corr.corr().drop(columns=['stationID', 'time', 'lineID']).drop(index=['stationID', 'time', 'lineID'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe agrupado por intervalos de 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "#Para agrupar por horas poner 'H' en la frecuencia del Grouper\n",
    "df_agrupado = df_agrupado.groupby(['stationID', pd.Grouper(freq='10T', level=0),'lineID' ,'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado.reset_index(inplace=True)\n",
    "mapeo_lineID = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    # Agrega más mapeos según sea necesario\n",
    "}\n",
    "\n",
    "# Aplicar la conversión utilizando el método map\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].map(mapeo_lineID)\n",
    "df_agrupado['lineID'] = df_agrupado['lineID'].astype('category')\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = df_agrupado.merge(meteodrop, on=['time'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['temp'].interpolate(method='linear', inplace=True)\n",
    "resultado['humidity'].interpolate(method='linear', inplace=True)\n",
    "resultado['windspeed'].interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta = resultado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['year'] = resultado['time'].dt.year\n",
    "resultado['month'] = resultado['time'].dt.month\n",
    "resultado['day'] = resultado['time'].dt.day\n",
    "resultado['hour'] = resultado['time'].dt.hour\n",
    "resultado['min'] = resultado['time'].dt.minute\n",
    "resultado.drop(columns=['time'], inplace=True)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = resultado_fecha_junta[(resultado_fecha_junta['stationID']==10) & (resultado_fecha_junta['time'].dt.day==20)]\n",
    "test_corr.corr().drop(columns=['stationID', 'time', 'lineID']).drop(index=['stationID', 'time', 'lineID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del df_agrupado\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del meteo, meteodrop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacion_mas_concurrente = resultado_fecha_junta.groupby('stationID').agg({'salida': 'sum', 'entrada': 'sum'}).reset_index()\n",
    "# Paso 2: Crea una nueva columna con la suma de 'salida' y 'entrada\n",
    "estacion_mas_concurrente['total'] = estacion_mas_concurrente['salida'] + estacion_mas_concurrente['entrada']\n",
    "# Paso 3: Encuentra la estación con el total más grande\n",
    "estacion_max_total = estacion_mas_concurrente[estacion_mas_concurrente['total'] == estacion_mas_concurrente['total'].max()]\n",
    "print(\"La estación con el total más grande para entrada y salida es:\")\n",
    "print(estacion_max_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = resultado_fecha_junta[resultado_fecha_junta['stationID']==15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))  # Establece el tamaño de la gráfica\n",
    "\n",
    "# Grafica la entrada y la salida en el eje Y contra 'time' en el eje X\n",
    "plt.plot(test['time'], test['entrada'], label='Entrada', marker='o')\n",
    "plt.plot(test['time'], test['salida'], label='Salida', marker='o')\n",
    "\n",
    "# Personaliza la gráfica\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valores de Entrada y Salida')\n",
    "plt.title('Valores de Entrada y Salida a lo largo del tiempo')\n",
    "plt.legend()\n",
    "\n",
    "# Rota las etiquetas del eje X para que sean legibles\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Muestra la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = resultado_fecha_junta[resultado_fecha_junta['stationID']==80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))  # Establece el tamaño de la gráfica\n",
    "\n",
    "# Grafica la entrada y la salida en el eje Y contra 'time' en el eje X\n",
    "plt.plot(test['time'], test['entrada'], label='Entrada', marker='o')\n",
    "plt.plot(test['time'], test['salida'], label='Salida', marker='o')\n",
    "\n",
    "# Personaliza la gráfica\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valores de Entrada y Salida')\n",
    "plt.title('Valores de Entrada y Salida a lo largo del tiempo')\n",
    "plt.legend()\n",
    "\n",
    "# Rota las etiquetas del eje X para que sean legibles\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Muestra la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = records[records['time'].dt.day < 12].copy()\n",
    "test = records[(records['time'].dt.day < 20) & (records['time'].dt.day > 12)].copy()\n",
    "pred = records[records['time'].dt.day > 20].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = records.set_index('time')\n",
    "df_agrupado = df_agrupado.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "df_agrupado.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df_agrupado.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['year'] = df_agrupado['time'].dt.year\n",
    "df_agrupado['month'] = df_agrupado['time'].dt.month\n",
    "df_agrupado['day'] = df_agrupado['time'].dt.day\n",
    "df_agrupado['hour'] = df_agrupado['time'].dt.hour\n",
    "df_agrupado.drop(columns=['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_agrupado[['stationID', 'year', 'month', 'day', 'hour']]\n",
    "y_entrada = df_agrupado['entrada']\n",
    "y_salida = df_agrupado['salida']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESIÓN LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide tus datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "X_train, X_test, y_entrada_train, y_entrada_test, y_salida_train, y_salida_test = train_test_split(X, y_entrada, y_salida, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea un modelo de regresión lineal para las entradas\n",
    "modelo_entrada = LinearRegression()\n",
    "modelo_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realiza predicciones para las entradas\n",
    "predicciones_entrada = modelo_entrada.predict(X_test)\n",
    "predicciones_entrada = np.round(predicciones_entrada).astype(int)\n",
    "\n",
    "# Calcula el error para las predicciones de entradas\n",
    "error_entrada = mean_squared_error(y_entrada_test, predicciones_entrada)\n",
    "print(f\"Error de entradas: {error_entrada}\")\n",
    "\n",
    "# Crea un modelo de regresión lineal para las salidas\n",
    "modelo_salida = LinearRegression()\n",
    "modelo_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realiza predicciones para las salidas\n",
    "predicciones_salida = modelo_salida.predict(X_test)\n",
    "predicciones_salida = np.round(predicciones_salida).astype(int)\n",
    "\n",
    "# Calcula el error para las predicciones de salidas\n",
    "error_salida = np.sqrt(mean_squared_error(y_salida_test, predicciones_salida))\n",
    "print(f\"Error de salidas: {error_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide tus datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "X_train, X_test, y_entrada_train, y_entrada_test, y_salida_train, y_salida_test = train_test_split(X, y_entrada, y_salida, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea un modelo de regresión lineal para las entradas\n",
    "modelo_entrada = LinearRegression()\n",
    "modelo_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realiza predicciones para las entradas\n",
    "predicciones_entrada = modelo_entrada.predict(X_test)\n",
    "\n",
    "# Calcula el error para las predicciones de entradas\n",
    "error_entrada = mean_squared_error(y_entrada_test, predicciones_entrada)\n",
    "print(f\"Error de entradas: {error_entrada}\")\n",
    "\n",
    "# Crea un modelo de regresión lineal para las salidas\n",
    "modelo_salida = LinearRegression()\n",
    "modelo_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realiza predicciones para las salidas\n",
    "predicciones_salida = modelo_salida.predict(X_test)\n",
    "\n",
    "# Calcula el error para las predicciones de salidas\n",
    "error_salida = np.sqrt(mean_squared_error(y_salida_test, predicciones_salida))\n",
    "print(f\"Error de salidas: {error_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_salida.size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada 10 min y Meteo incluido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = resultado[['stationID', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']]\n",
    "y_entrada = resultado['entrada']\n",
    "y_salida = resultado['salida']\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide tus datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "X_train, X_test, y_entrada_train, y_entrada_test, y_salida_train, y_salida_test = train_test_split(X_scaled, y_entrada, y_salida, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea un modelo de regresión lineal para las entradas\n",
    "modelo_entrada = LinearRegression()\n",
    "modelo_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realiza predicciones para las entradas\n",
    "predicciones_entrada = modelo_entrada.predict(X_test)\n",
    "predicciones_entrada = np.round(predicciones_entrada).astype(int)\n",
    "\n",
    "# Calcula el error para las predicciones de entradas\n",
    "error_entrada =  np.sqrt(mean_squared_error(y_entrada_test, predicciones_entrada))\n",
    "print(f\"Error de entradas: {error_entrada}\")\n",
    "\n",
    "# Crea un modelo de regresión lineal para las salidas\n",
    "modelo_salida = LinearRegression()\n",
    "modelo_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realiza predicciones para las salidas\n",
    "predicciones_salida = modelo_salida.predict(X_test)\n",
    "predicciones_salida = np.round(predicciones_salida).astype(int)\n",
    "\n",
    "# Calcula el error para las predicciones de salidas\n",
    "error_salida = np.sqrt(mean_squared_error(y_salida_test, predicciones_salida))\n",
    "print(f\"Error de salidas: {error_salida}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LONG-SHORT TERM MEMORY (LSTM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hora 1 estación sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "   os.environ['PYTHONHASHSEED']=str(2)\n",
    "   tf.random.set_seed(2)\n",
    "   np.random.seed(2)\n",
    "   random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID','temp','humidity','windspeed','lineID'])\n",
    "station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(station_data[['entrada', 'salida']])\n",
    "\n",
    "# Definir la longitud de la secuencia temporal\n",
    "seq_length = 18  # Por ejemplo, utilizar las últimas 24 horas para predecir las próximas horas, pero utilizamos 18 porque no se toman datos de las 00:00 a las 04:00\n",
    "\n",
    "# Crear secuencias temporales y etiquetas\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length]        \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X, y = create_sequences(scaled_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "train_size = int(len(X) * 0.8)  # Puedes ajustar la proporción según tus necesidades\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Crear y entrenar el modelo LSTM\n",
    "model = Sequential()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add(LSTM(300, activation='relu', input_shape=(seq_length, 2)))  # 2 características: 'entrada' y 'salida'\n",
    "model.add(Dense(2))  # 2 salidas para 'entrada' y 'salida'\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')  # Puedes usar otra función de pérdida según tu problema\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=seq_length)  # Ajusta los hiperparámetros según tus necesidades\n",
    "\n",
    "# Realizar predicciones\n",
    "predicted_data = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertir la escala de las predicciones para obtener valores reales\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "# Desescalar los datos de prueba y las predicciones para obtener valores reales\n",
    "y_test_actual = scaler.inverse_transform(y_test)\n",
    "# Crear el gráfico\n",
    "time_range = range(len(y_test_actual))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 0], label='Valor Real de Entrada', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 0], label='Predicción de Entrada', marker='o', linestyle='--')\n",
    "plt.plot(time_range, y_test_actual[:, 1], label='Valor Real de Salida', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 1], label='Predicción de Salida', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Entrada y Salida para la estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 0], label='Valor Real de Entrada', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 0], label='Predicción de Entrada', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Entrada para la Estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 1], label='Valor Real de Salida', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 1], label='Predicción de Salida', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Salida para la Estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "# Calcula el coeficiente de determinación (R-cuadrado)\n",
    "r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-cuadrado:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hora 1 estación con METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(station_data[['entrada', 'salida', 'temp', 'humidity', 'windspeed']])\n",
    "\n",
    "# Escalar los datos a predecir\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit_transform(station_data[['entrada', 'salida']])\n",
    "\n",
    "# Definir la longitud de la secuencia temporal\n",
    "seq_length = 18  # Por ejemplo, utilizar las últimas 24 horas para predecir las próximas horas, pero utilizamos 18 porque no se toman datos de las 00:00 a las 04:00\n",
    "\n",
    "# Crear secuencias temporales y etiquetas\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length]        \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "y = y[:, :-3] #Solo queremos predecir las dos primeras variables, entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "train_size = int(len(X) * 0.8)  # Puedes ajustar la proporción según tus necesidades\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "reset_random_seeds()\n",
    "# Crear y entrenar el modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(500, activation='relu', input_shape=(seq_length, 5)))  # 2 características: 'entrada' y 'salida'\n",
    "model.add(Dense(2))  # 2 salidas para 'entrada' y 'salida'\n",
    "model.compile(optimizer='adam', loss='mse')  # Puedes usar otra función de pérdida según tu problema\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=seq_length)  # Ajusta los hiperparámetros según tus necesidades\n",
    "\n",
    "# Realizar predicciones\n",
    "predicted_data = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertir la escala de las predicciones para obtener valores reales\n",
    "predicted_data = scaler_y.inverse_transform(predicted_data)\n",
    "# Desescalar los datos de prueba y las predicciones para obtener valores reales\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "# Crear el gráfico\n",
    "time_range = range(len(y_test_actual))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 0], label='Valor Real de Entrada', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 0], label='Predicción de Entrada', marker='o', linestyle='--')\n",
    "plt.plot(time_range, y_test_actual[:, 1], label='Valor Real de Salida', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 1], label='Predicción de Salida', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Entrada y Salida para la estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "# Calcula el coeficiente de determinación (R-cuadrado)\n",
    "r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-cuadrado:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Min 1 estación Sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID','temp','humidity','windspeed','lineID'])\n",
    "station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(station_data[['entrada', 'salida']])\n",
    "\n",
    "# Definir la longitud de la secuencia temporal\n",
    "seq_length = 108  # Por ejemplo, utilizar las últimas 24 horas para predecir las próximas horas, pero utilizamos 18 porque no se toman datos de las 00:00 a las 04:00\n",
    "\n",
    "# Crear secuencias temporales y etiquetas\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length]        \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X, y = create_sequences(scaled_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "train_size = int(len(X) * 0.8)  # Puedes ajustar la proporción según tus necesidades\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Crear y entrenar el modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 2)))  # 2 características: 'entrada' y 'salida'\n",
    "model.add(Dense(2))  # 2 salidas para 'entrada' y 'salida'\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')  # Puedes usar otra función de pérdida según tu problema\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=seq_length)  # Ajusta los hiperparámetros según tus necesidades\n",
    "\n",
    "# Realizar predicciones\n",
    "predicted_data = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertir la escala de las predicciones para obtener valores reales\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "# Desescalar los datos de prueba y las predicciones para obtener valores reales\n",
    "y_test_actual = scaler.inverse_transform(y_test)\n",
    "# Crear el gráfico\n",
    "time_range = range(len(y_test_actual))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 0], label='Valor Real de Entrada', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 0], label='Predicción de Entrada', marker='o', linestyle='--')\n",
    "plt.plot(time_range, y_test_actual[:, 1], label='Valor Real de Salida', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 1], label='Predicción de Salida', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Entrada y Salida para la estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "# Calcula el coeficiente de determinación (R-cuadrado)\n",
    "r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-cuadrado:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Min 1 estación con METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(station_data[['entrada', 'salida', 'temp', 'humidity', 'windspeed']])\n",
    "\n",
    "# Escalar los datos a predecir\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit_transform(station_data[['entrada', 'salida']])\n",
    "\n",
    "# Definir la longitud de la secuencia temporal\n",
    "seq_length = 108  # Por ejemplo, utilizar las últimas 24 horas para predecir las próximas horas, pero utilizamos 18 porque no se toman datos de las 00:00 a las 04:00\n",
    "\n",
    "# Crear secuencias temporales y etiquetas\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length]        \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "y = y[:, :-3] #Solo queremos predecir las dos primeras variables, entrada y salida\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "train_size = int(len(X) * 0.8)  # Puedes ajustar la proporción según tus necesidades\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Crear y entrenar el modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 5)))  #5 características\n",
    "model.add(Dense(2))  # 2 salidas para 'entrada' y 'salida'\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')  # Puedes usar otra función de pérdida según tu problema\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=seq_length)  # Ajusta los hiperparámetros según tus necesidades\n",
    "\n",
    "# Realizar predicciones\n",
    "predicted_data = model.predict(X_test)\n",
    "\n",
    "# Invertir la escala de las predicciones para obtener valores reales\n",
    "predicted_data = scaler_y.inverse_transform(predicted_data)\n",
    "# Desescalar los datos de prueba y las predicciones para obtener valores reales\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "# Crear el gráfico\n",
    "time_range = range(len(y_test_actual))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_range, y_test_actual[:, 0], label='Valor Real de Entrada', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 0], label='Predicción de Entrada', marker='o', linestyle='--')\n",
    "plt.plot(time_range, y_test_actual[:, 1], label='Valor Real de Salida', marker='o', linestyle='-')\n",
    "plt.plot(time_range, predicted_data[:, 1], label='Predicción de Salida', marker='o', linestyle='--')\n",
    "\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicción de Entrada y Salida para la estación 0')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calcula el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "# Calcula el coeficiente de determinación (R-cuadrado)\n",
    "r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-cuadrado:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "# Calcula el coeficiente de determinación (R-cuadrado)\n",
    "r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "#Calcula el MAPE\n",
    "# Encuentra el valor mínimo y máximo de los datos reales y de predicción\n",
    "min_real = np.min(y_test_actual)\n",
    "max_real = np.max(y_test_actual)\n",
    "min_pred = np.min(predicted_data)\n",
    "max_pred = np.max(predicted_data)\n",
    "\n",
    "# Escala los datos reales y de predicción al rango de 1 a 10\n",
    "scaled_real = 1 + (9 * (y_test_actual - min_real) / (max_real - min_real))\n",
    "scaled_pred = 1 + (9 * (predicted_data - min_pred) / (max_pred - min_pred))\n",
    "\n",
    "n = len(scaled_real)\n",
    "mape = (1/n) * np.sum(np.abs((scaled_real - scaled_pred) / scaled_real) * 100)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-cuadrado:\", r2)\n",
    "print(\"MAPE:\", mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con todas las estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones = resultado_fecha_junta['stationID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rmse = None\n",
    "best_r2 = None\n",
    "best_station = None\n",
    "mape_arr = []\n",
    "for est in estaciones:\n",
    "\n",
    "    station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == est]\n",
    "\n",
    "    # Escalar los datos\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(station_data[['entrada', 'salida', 'temp', 'humidity', 'windspeed']])\n",
    "\n",
    "    # Escalar los datos a predecir\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit_transform(station_data[['entrada', 'salida']])\n",
    "\n",
    "    # Definir la longitud de la secuencia temporal\n",
    "    seq_length = 108  # Por ejemplo, utilizar las últimas 24 horas para predecir las próximas horas, pero utilizamos 18 porque no se toman datos de las 00:00 a las 04:00\n",
    "\n",
    "    # Crear secuencias temporales y etiquetas\n",
    "    def create_sequences(data, seq_length):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            seq = data[i:i+seq_length]\n",
    "            label = data[i+seq_length]        \n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "        return np.array(sequences), np.array(labels)\n",
    "\n",
    "    X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "    y = y[:, :-4] #Solo queremos predecir las dos primeras variables, entrada y salida\n",
    "\n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    train_size = int(len(X) * 0.8)  # Puedes ajustar la proporción según tus necesidades\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Crear y entrenar el modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(seq_length, 5)))  #6 características\n",
    "    model.add(Dense(2))  # 2 salidas para 'entrada' y 'salida'\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')  # Puedes usar otra función de pérdida según tu problema\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=seq_length)  # Ajusta los hiperparámetros según tus necesidades\n",
    "\n",
    "    # Realizar predicciones\n",
    "    predicted_data = model.predict(X_test)\n",
    "\n",
    "    # Invertir la escala de las predicciones para obtener valores reales\n",
    "    predicted_data = scaler_y.inverse_transform(predicted_data)\n",
    "    # Desescalar los datos de prueba y las predicciones para obtener valores reales\n",
    "    y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # Calcula el RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_actual, predicted_data))\n",
    "\n",
    "    # Calcula el coeficiente de determinación (R-cuadrado)\n",
    "    r2 = r2_score(y_test_actual, predicted_data)\n",
    "\n",
    "    #Calcula el MAPE\n",
    "    # Encuentra el valor mínimo y máximo de los datos reales y de predicción\n",
    "    min_real = np.min(y_test_actual)\n",
    "    max_real = np.max(y_test_actual)\n",
    "    min_pred = np.min(predicted_data)\n",
    "    max_pred = np.max(predicted_data)\n",
    "\n",
    "    # Escala los datos reales y de predicción al rango de 1 a 10\n",
    "    scaled_real = 1 + (9 * (y_test_actual - min_real) / (max_real - min_real))\n",
    "    scaled_pred = 1 + (9 * (predicted_data - min_pred) / (max_pred - min_pred))\n",
    "\n",
    "    n = len(scaled_real)\n",
    "    mape = (1/n) * np.sum(np.abs((scaled_real - scaled_pred) / scaled_real) * 100)\n",
    "\n",
    "    mape_arr.append(mape)\n",
    "\n",
    "    if(best_rmse is None or rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_r2 = r2\n",
    "        best_station = est\n",
    "\n",
    "mape_total = np.mean(mape_arr)\n",
    "mape_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intento manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_df = records.set_index('time')\n",
    "arima_df = arima_df.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "arima_df.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "arima_df.reset_index(inplace=True)\n",
    "arima_df.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = arima_df[arima_df['stationID'] == 0]\n",
    "station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(station_data[\"salida\"], label=\"Salida\")\n",
    "plt.plot(station_data[\"entrada\"], label=\"Entrada\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Datos de Salida y Entrada por Hora\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza una prueba de estacionariedad\n",
    "def adf_test(series):\n",
    "    result = adfuller(series, autolag=\"AIC\")\n",
    "    print(\"ADF Statistic:\", result[0])\n",
    "    print(\"p-value:\", result[1])\n",
    "    print(\"Critical Values:\", result[4])\n",
    "\n",
    "adf_test(station_data[\"salida\"])  # Realiza la prueba para la serie de salida\n",
    "adf_test(station_data[\"entrada\"])  # Realiza la prueba para la serie de entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencia los datos si es necesario para hacerlos estacionarios\n",
    "station_data['salida_diff'] = station_data['salida'].diff().dropna()\n",
    "station_data['entrada_diff'] = station_data['entrada'].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza las series diferenciadas\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(station_data[\"salida_diff\"], label=\"Diferencia de Salida\")\n",
    "plt.plot(station_data[\"entrada_diff\"], label=\"Diferencia de Entrada\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Diferencia de Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Series Diferenciadas de Salida y Entrada por Hora\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza un análisis de autocorrelación y autocorrelación parcial\n",
    "plot_acf(station_data[\"salida_diff\"], lags=40)\n",
    "plot_pacf(station_data[\"salida_diff\"], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(station_data[\"entrada_diff\"], lags=40)\n",
    "plot_pacf(station_data[\"entrada_diff\"], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta el modelo ARIMA\n",
    "model_salida = ARIMA(station_data[\"salida\"], order=(1, 1, 1))\n",
    "model_entrada = ARIMA(station_data[\"entrada\"], order=(1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta el modelo a los datos\n",
    "model_salida_fit = model_salida.fit()\n",
    "model_entrada_fit = model_entrada.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza predicciones\n",
    "n_forecast = 24  # Número de pasos hacia adelante a predecir\n",
    "\n",
    "forecast_salida = model_salida_fit.forecast(steps=n_forecast)\n",
    "forecast_entrada = model_entrada_fit.forecast(steps=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza las predicciones\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(station_data.index, station_data[\"salida\"], label=\"Salida (Observado)\")\n",
    "plt.plot(pd.date_range(start=station_data.index[-1], periods=n_forecast, freq=\"H\"), forecast_salida, label=\"Salida (Predicción)\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicción de Salida por Hora\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(station_data.index, station_data[\"entrada\"], label=\"Entrada (Observado)\")\n",
    "plt.plot(pd.date_range(start=station_data.index[-1], periods=n_forecast, freq=\"H\"), forecast_entrada, label=\"Entrada (Predicción)\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicción de Entrada por Hora\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intento automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_df = records.set_index('time')\n",
    "arima_df = arima_df.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "arima_df.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "arima_df.reset_index(inplace=True)\n",
    "arima_df.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = arima_df[arima_df['stationID'] == 0]\n",
    "station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa tus datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data = station_data.iloc[:train_size]\n",
    "test_data = station_data.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_entrada = auto_arima(train_data['entrada'], seasonal=True, stepwise=True, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_salida = auto_arima(train_data['salida'], seasonal=True, stepwise=True, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta el modelo ARIMA con los parámetros óptimos encontrados\n",
    "model_entrada.fit(train_data['entrada'])\n",
    "model_salida.fit(train_data['salida'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza predicciones en el conjunto de prueba\n",
    "predictions_entrada = model_entrada.predict(n_periods=len(test_data))\n",
    "predictions_salida = model_salida.predict(n_periods=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza las predicciones\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index, test_data[\"salida\"], label=\"Salida (Observado)\")\n",
    "plt.plot(pd.date_range(start=test_data.index[-1], periods=len(test_data), freq=\"H\"), predictions_salida, label=\"Salida (Predicción)\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicción de Salida por Hora\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index, test_data[\"entrada\"], label=\"Entrada (Observado)\")\n",
    "plt.plot(pd.date_range(start=test_data.index[-1], periods=len(test_data), freq=\"H\"), predictions_entrada, label=\"Entrada (Predicción)\")\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicción de Entrada por Hora\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_entrada = np.sqrt(mean_squared_error(test_data['entrada'], predictions_entrada))\n",
    "print(f'RMSE: {rmse_entrada}')\n",
    "rmse_salida = np.sqrt(mean_squared_error(test_data['salida'], predictions_salida))\n",
    "print(f'RMSE: {rmse_salida}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del arima_df\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROPHET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hora Estación única sin METEO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_salida = station_data.iloc[:train_size]\n",
    "test_data_salida = station_data.iloc[train_size:]\n",
    "\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "\n",
    "# model.add_regressor('lineID')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_salida)\n",
    "# Realizar las predicciones\n",
    "forecast_salida = model.predict(test_data_salida)\n",
    "# Visualizar las predicciones\n",
    "rmse_salida = np.sqrt(mean_squared_error(test_data_salida['y'], forecast_salida['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data_salida['y'],forecast_salida['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = model.plot(forecast_salida)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID', 'salida','temp','humidity','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'entrada': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_entrada = station_data.iloc[:train_size]\n",
    "test_data_entrada = station_data.iloc[train_size:]\n",
    "\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "# model.add_regressor('lineID')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_entrada)\n",
    "# Realizar las predicciones\n",
    "forecast_entrada = model.predict(test_data_entrada)\n",
    "rmse_entrada = np.sqrt(mean_squared_error(test_data_entrada['y'], forecast_entrada['yhat']))\n",
    "print(f'RMSE: {rmse_entrada}')\n",
    "r2_entrada = r2_score(test_data_entrada['y'],forecast_entrada['yhat'])\n",
    "print(f'R^2: {r2_entrada}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred = np.array([forecast_entrada['yhat'], forecast_salida['yhat']]).T\n",
    "comb_real = np.array([test_data_entrada['y'], test_data_salida['y']]).T\n",
    "rmse = np.sqrt(mean_squared_error(comb_real, comb_pred))\n",
    "r2 = r2_score(comb_real, comb_pred)\n",
    "print(\"RMSE combinado:\", rmse)\n",
    "print(\"R² combinado:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 hora Estación única con METEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "#station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_salida = station_data.iloc[:train_size]\n",
    "test_data_salida = station_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('entrada')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_salida)\n",
    "# Realizar las predicciones\n",
    "forecast_salida = model.predict(test_data_salida)\n",
    "rmse_salida = np.sqrt(mean_squared_error(test_data_salida['y'], forecast_salida['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data_salida['y'],forecast_salida['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta_hora[resultado_fecha_junta_hora['stationID'] == 0]\n",
    "#station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'entrada': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_entrada = station_data.iloc[:train_size]\n",
    "test_data_entrada = station_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('salida')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_entrada)\n",
    "# Realizar las predicciones\n",
    "forecast_entrada = model.predict(test_data_entrada)\n",
    "rmse_entrada = np.sqrt(mean_squared_error(test_data_entrada['y'], forecast_entrada['yhat']))\n",
    "print(f'RMSE: {rmse_entrada}')\n",
    "r2_entrada = r2_score(test_data_entrada['y'],forecast_entrada['yhat'])\n",
    "print(f'R^2: {r2_entrada}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred = np.array([forecast_entrada['yhat'], forecast_salida['yhat']]).T\n",
    "comb_real = np.array([test_data_entrada['y'], test_data_salida['y']]).T\n",
    "rmse = np.sqrt(mean_squared_error(comb_real, comb_pred))\n",
    "r2 = r2_score(comb_real, comb_pred)\n",
    "print(\"RMSE combinado:\", rmse)\n",
    "print(\"R² combinado:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Min Estación única sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_salida = station_data.iloc[:train_size]\n",
    "test_data_salida = station_data.iloc[train_size:]\n",
    "\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "# model.add_regressor('lineID')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_salida)\n",
    "# Realizar las predicciones\n",
    "forecast_salida = model.predict(test_data_salida)\n",
    "# Visualizar las predicciones\n",
    "rmse_salida = np.sqrt(mean_squared_error(test_data_salida['y'], forecast_salida['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data_salida['y'],forecast_salida['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "station_data = station_data.drop(columns=['stationID', 'salida','temp','humidity','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'entrada': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_entrada = station_data.iloc[:train_size]\n",
    "test_data_entrada = station_data.iloc[train_size:]\n",
    "\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "# model.add_regressor('lineID')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_entrada)\n",
    "# Realizar las predicciones\n",
    "forecast_entrada = model.predict(test_data_entrada)\n",
    "rmse_entrada = np.sqrt(mean_squared_error(test_data_entrada['y'], forecast_entrada['yhat']))\n",
    "print(f'RMSE: {rmse_entrada}')\n",
    "r2_entrada = r2_score(test_data_entrada['y'],forecast_entrada['yhat'])\n",
    "print(f'R^2: {r2_entrada}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred = np.array([forecast_entrada['yhat'], forecast_salida['yhat']]).T\n",
    "comb_real = np.array([test_data_entrada['y'], test_data_salida['y']]).T\n",
    "rmse = np.sqrt(mean_squared_error(comb_real, comb_pred))\n",
    "r2 = r2_score(comb_real, comb_pred)\n",
    "print(\"RMSE combinado:\", rmse)\n",
    "print(\"R² combinado:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Min Estación única con METEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "#station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_salida = station_data.iloc[:train_size]\n",
    "test_data_salida = station_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('entrada')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_salida)\n",
    "# Realizar las predicciones\n",
    "forecast_salida = model.predict(test_data_salida)\n",
    "rmse_salida = np.sqrt(mean_squared_error(test_data_salida['y'], forecast_salida['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data_salida['y'],forecast_salida['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "#station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "station_data.rename(columns={'time': 'ds', 'entrada': 'y'},inplace=True)\n",
    "\n",
    "train_size = int(len(station_data) * 0.8)\n",
    "train_data_entrada = station_data.iloc[:train_size]\n",
    "test_data_entrada = station_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('salida')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data_entrada)\n",
    "# Realizar las predicciones\n",
    "forecast_entrada = model.predict(test_data_entrada)\n",
    "rmse_entrada = np.sqrt(mean_squared_error(test_data_entrada['y'], forecast_entrada['yhat']))\n",
    "print(f'RMSE: {rmse_entrada}')\n",
    "r2_entrada = r2_score(test_data_entrada['y'],forecast_entrada['yhat'])\n",
    "print(f'R^2: {r2_entrada}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_pred = np.array([forecast_entrada['yhat'], forecast_salida['yhat']]).T\n",
    "comb_real = np.array([test_data_entrada['y'], test_data_salida['y']]).T\n",
    "rmse = np.sqrt(mean_squared_error(comb_real, comb_pred))\n",
    "r2 = r2_score(comb_real, comb_pred)\n",
    "print(\"RMSE combinado:\", rmse)\n",
    "print(\"R² combinado:\", r2)\n",
    "mape = np.mean(np.abs((comb_real - comb_pred)/np.maximum(comb_real,1)))\n",
    "print(\"MAPE:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con todas las estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "best_rmse = None\n",
    "best_r2 = None\n",
    "best_station = None\n",
    "mape_arr = []\n",
    "for est in estaciones:\n",
    "\n",
    "    # SALIDA\n",
    "    station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == est]\n",
    "    #station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "    station_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "\n",
    "    train_size = int(len(station_data) * 0.8)\n",
    "    train_data_salida = station_data.iloc[:train_size]\n",
    "    test_data_salida = station_data.iloc[train_size:]\n",
    "    # Crear un modelo Prophet\n",
    "    model = Prophet()\n",
    "    model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "    model.add_regressor('lineID')\n",
    "    model.add_regressor('entrada')\n",
    "    model.add_regressor('temp')\n",
    "    model.add_regressor('humidity')\n",
    "    model.add_regressor('windspeed')\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(train_data_salida)\n",
    "    # Realizar las predicciones\n",
    "    forecast_salida = model.predict(test_data_salida)\n",
    "    rmse_salida = np.sqrt(mean_squared_error(test_data_salida['y'], forecast_salida['yhat']))\n",
    "    r2_salida = r2_score(test_data_salida['y'],forecast_salida['yhat'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ENTRADA\n",
    "    station_data = resultado_fecha_junta[resultado_fecha_junta['stationID'] == 0]\n",
    "    #station_data = station_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'])\n",
    "    station_data.rename(columns={'time': 'ds', 'entrada': 'y'},inplace=True)\n",
    "\n",
    "    train_size = int(len(station_data) * 0.8)\n",
    "    train_data_entrada = station_data.iloc[:train_size]\n",
    "    test_data_entrada = station_data.iloc[train_size:]\n",
    "    # Crear un modelo Prophet\n",
    "    model = Prophet()\n",
    "    model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "    model.add_regressor('lineID')\n",
    "    model.add_regressor('salida')\n",
    "    model.add_regressor('temp')\n",
    "    model.add_regressor('humidity')\n",
    "    model.add_regressor('windspeed')\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(train_data_entrada)\n",
    "    # Realizar las predicciones\n",
    "    forecast_entrada = model.predict(test_data_entrada)\n",
    "    rmse_entrada = np.sqrt(mean_squared_error(test_data_entrada['y'], forecast_entrada['yhat']))\n",
    "    r2_entrada = r2_score(test_data_entrada['y'],forecast_entrada['yhat'])\n",
    "\n",
    "    print(forecast_entrada['yhat'].shape)\n",
    "    print(forecast_salida['yhat'].shape)\n",
    "    comb_pred = np.array([forecast_entrada['yhat'], forecast_salida['yhat']]).T\n",
    "    comb_real = np.array([test_data_entrada['y'], test_data_salida['y']]).T\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(comb_real, comb_pred))\n",
    "    r2 = r2_score(comb_real, comb_pred)\n",
    "\n",
    "    print('RMSE',rmse)\n",
    "\n",
    "    #Calcula el MAPE\n",
    "    mape = np.mean(np.abs((comb_real - comb_pred)/np.maximum(comb_real,1)))*100\n",
    "    mape_arr.append(mape)\n",
    "\n",
    "    if(best_rmse is None or rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_r2 = r2\n",
    "        best_station = est\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "mape_total = np.mean(mape_arr)\n",
    "mape_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 min Todas Estaciones con METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data = resultado_fecha_junta.copy()\n",
    "all_stations_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "all_stations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(all_stations_data) * 0.8)\n",
    "train_data = all_stations_data.iloc[:train_size]\n",
    "test_data = all_stations_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('stationID')\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('entrada')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('precip')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data)\n",
    "# Realizar las predicciones\n",
    "forecast = model.predict(test_data)\n",
    "# Visualizar las predicciones\n",
    "fig = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_salida = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data['y'],forecast['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 min Todas Estaciones sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data = resultado_fecha_junta.copy()\n",
    "all_stations_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "all_stations_data.drop(columns=['stationID', 'entrada','temp','humidity','precip','windspeed','lineID'],inplace=True)\n",
    "all_stations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(all_stations_data) * 0.8)\n",
    "train_data = all_stations_data.iloc[:train_size]\n",
    "test_data = all_stations_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "# model.add_regressor('stationID')\n",
    "# model.add_regressor('lineID')\n",
    "# model.add_regressor('entrada')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data)\n",
    "# Realizar las predicciones\n",
    "forecast = model.predict(test_data)\n",
    "# Visualizar las predicciones\n",
    "fig = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_salida = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data['y'],forecast['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hora Todas Estaciones con METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_fecha_junta_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data = resultado_fecha_junta_hora.copy()\n",
    "all_stations_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "all_stations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(all_stations_data) * 0.8)\n",
    "train_data = all_stations_data.iloc[:train_size]\n",
    "test_data = all_stations_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('stationID')\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('entrada')\n",
    "model.add_regressor('temp')\n",
    "model.add_regressor('humidity')\n",
    "model.add_regressor('precip')\n",
    "model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data)\n",
    "# Realizar las predicciones\n",
    "forecast = model.predict(test_data)\n",
    "# Visualizar las predicciones\n",
    "fig = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_salida = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data['y'],forecast['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hora Todas Estaciones sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_data = resultado_fecha_junta_hora.copy()\n",
    "all_stations_data.rename(columns={'time': 'ds', 'salida': 'y'},inplace=True)\n",
    "all_stations_data.drop(columns=['temp','humidity','precip','windspeed'],inplace=True)\n",
    "all_stations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(all_stations_data) * 0.8)\n",
    "train_data = all_stations_data.iloc[:train_size]\n",
    "test_data = all_stations_data.iloc[train_size:]\n",
    "# Crear un modelo Prophet\n",
    "model = Prophet()\n",
    "model.random_state = 42  # Reemplaza 42 con la semilla que desees\n",
    "model.add_regressor('stationID')\n",
    "model.add_regressor('lineID')\n",
    "model.add_regressor('entrada')\n",
    "# model.add_regressor('temp')\n",
    "# model.add_regressor('humidity')\n",
    "# model.add_regressor('precip')\n",
    "# model.add_regressor('windspeed')\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "model.fit(train_data)\n",
    "# Realizar las predicciones\n",
    "forecast = model.predict(test_data)\n",
    "# Visualizar las predicciones\n",
    "fig = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_salida = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
    "print(f'RMSE: {rmse_salida}')\n",
    "r2_salida = r2_score(test_data['y'],forecast['yhat'])\n",
    "print(f'R^2: {r2_salida}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_df = records.set_index('time')\n",
    "rnn_df = rnn_df.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "rnn_df.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "rnn_df.reset_index(inplace=True)\n",
    "rnn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_df['year'] = rnn_df['time'].dt.year\n",
    "rnn_df['month'] = rnn_df['time'].dt.month\n",
    "rnn_df['day'] = rnn_df['time'].dt.day\n",
    "rnn_df['hour'] = rnn_df['time'].dt.hour\n",
    "rnn_df.drop(columns=['time'], inplace=True)\n",
    "rnn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí, seleccionaremos las características (estación y hora) y el objetivo (salida y entrada)\n",
    "X = rnn_df[['stationID', 'year', 'month', 'day', 'hour']].values\n",
    "y_salida = rnn_df['salida'].values\n",
    "y_entrada = rnn_df['entrada'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"salida\"\n",
    "rf_salida = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_salida.fit(X_train, y_salida_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones para la variable \"salida\"\n",
    "y_salida_pred = rf_salida.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"entrada\"\n",
    "rf_entrada = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "y_entrada_pred = rf_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de valores reales y predicciones para la columna \"salida\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_salida_test, label='Valores Reales (Salida)', marker='o')\n",
    "plt.plot(y_salida_pred, label='Predicciones (Salida)', linestyle='--', marker='x')\n",
    "\n",
    "# Configuración de etiquetas y leyenda\n",
    "plt.xlabel('Fecha y Hora')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Valores Reales vs. Predicciones (Salida)')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gráfico para la variable \"salida\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_salida_test, y_salida_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Salida)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico para la variable \"entrada\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_entrada_test, y_entrada_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Entrada)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_entrada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada 10 min Meteo incluido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado[['stationID', 'year', 'month', 'day', 'hour','min', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado['salida'].values\n",
    "y_entrada = resultado['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_salida = RandomForestRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Crear y entrenar el modelo Random Forest para la variable \"salida\"\n",
    "grid_search = GridSearchCV(rf_salida, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=6)\n",
    "grid_search.fit(X_train, y_salida_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_salida_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar mejor modelo\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_random_forest_model.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos con mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"salida\"\n",
    "rf_salida = RandomForestRegressor(n_estimators=300, max_depth=20,random_state=42)\n",
    "rf_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"salida\"\n",
    "y_salida_pred = rf_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"entrada\"\n",
    "rf_entrada = RandomForestRegressor(n_estimators=300, max_depth=20,random_state=42)\n",
    "rf_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "y_entrada_pred = rf_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada 1 hora con datos Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado_hora[['stationID', 'year', 'month', 'day', 'hour', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado_hora['salida'].values\n",
    "y_entrada = resultado_hora['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"salida\"\n",
    "rf_salida = RandomForestRegressor(n_estimators=300, max_depth=20,random_state=42)\n",
    "rf_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"salida\"\n",
    "y_salida_pred = rf_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo Random Forest para la variable \"entrada\"\n",
    "rf_entrada = RandomForestRegressor(n_estimators=300, max_depth=20,random_state=42)\n",
    "rf_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "y_entrada_pred = rf_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 min Estación única sin METEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado_hora[['stationID', 'year', 'month', 'day', 'hour', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado_hora['salida'].values\n",
    "y_entrada = resultado_hora['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(resultado) * 0.8)\n",
    "train_data = resultado.iloc[:train_size]\n",
    "test_data = resultado.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[['stationID', 'year', 'month', 'day', 'hour', 'min', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "X_test = test_data[['stationID', 'year', 'month', 'day', 'hour', 'min', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida_train = train_data['salida'].values\n",
    "y_salida_test = test_data['salida'].values\n",
    "y_entrada_train = train_data['entrada'].values\n",
    "y_entrada_test = test_data['entrada'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_salida_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_salida = xgb.XGBRegressor(n_estimators = 300, learning_rate = 0.1, max_depth = 12, random_state=42)\n",
    "# Realizar predicciones para la variable \"salida\"\n",
    "xgb_salida.fit(X_train, y_salida_train)\n",
    "y_salida_pred = xgb_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"salida\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_df = records.set_index('time')\n",
    "rnn_df = rnn_df.groupby(['stationID', pd.Grouper(freq='H', level=0), 'status'])['userID'].count().unstack(fill_value=0)\n",
    "rnn_df.rename(columns={0: 'salida', 1: 'entrada'}, inplace=True)\n",
    "rnn_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "rnn_df['year'] = rnn_df['time'].dt.year\n",
    "rnn_df['month'] = rnn_df['time'].dt.month\n",
    "rnn_df['day'] = rnn_df['time'].dt.day\n",
    "rnn_df['hour'] = rnn_df['time'].dt.hour\n",
    "rnn_df.drop(columns=['time'], inplace=True)\n",
    "\n",
    "# Aquí, seleccionaremos las características (estación y hora) y el objetivo (salida y entrada)\n",
    "X = rnn_df[['stationID', 'year', 'month', 'day', 'hour']].values\n",
    "y_salida = rnn_df['salida'].values\n",
    "y_entrada = rnn_df['entrada'].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo XGBoost para la variable \"salida\"\n",
    "xgb_salida = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_salida.fit(X_train, y_salida_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"salida\"\n",
    "y_salida_pred = xgb_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"salida\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo XGBoost para la variable \"entrada\"\n",
    "xgb_entrada = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_entrada.fit(X_train, y_entrada_train)\n",
    "\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "y_entrada_pred = xgb_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"entrada\"\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la variable \"salida\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_salida_test, y_salida_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Salida)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico para la variable \"entrada\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_entrada_test, y_entrada_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Entrada)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada 10 min y Meteo incluido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado[['stationID', 'year', 'month', 'day', 'hour', 'min', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado['salida'].values\n",
    "y_entrada = resultado['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [10, 12, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=6)\n",
    "grid_search.fit(X_train, y_salida_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo para la variable \"salida\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, 'best_xgboost_model_salida_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [10, 12, 15]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=6)\n",
    "grid_search.fit(X_train, y_entrada_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo para la variable \"salida\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_entrada_test, y_pred))\n",
    "r2_salida = r2_score(y_entrada_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, 'best_xgboost_model_entrada_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usamos los mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado[['stationID', 'year', 'month', 'day', 'hour', 'min', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado['salida'].values\n",
    "y_entrada = resultado['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_salida = xgb.XGBRegressor(n_estimators = 300, learning_rate = 0.1, max_depth = 12, random_state=42)\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "xgb_salida.fit(X_train, y_salida_train)\n",
    "y_salida_pred = xgb_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"entrada\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_entrada = xgb.XGBRegressor(n_estimators = 300, learning_rate = 0.1, max_depth = 12, random_state=42)\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "xgb_entrada.fit(X_train, y_entrada_train)\n",
    "y_entrada_pred = xgb_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"entrada\"\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_entrada, 'best_xgboost_model_entrada.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la variable \"salida\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_salida_test, y_salida_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Salida)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico para la variable \"entrada\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_entrada_test, y_entrada_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Entrada)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de valores reales y predicciones para la columna \"salida\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_entrada_test, label='Valores Reales (Entrada)', marker='o')\n",
    "plt.plot(y_entrada_pred, label='Predicciones (Entrada)', linestyle='--', marker='x')\n",
    "\n",
    "# Configuración de etiquetas y leyenda\n",
    "plt.xlabel('Fecha y Hora')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Valores Reales vs. Predicciones (Entrada)')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada 1 hora con datos Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resultado_hora[['stationID', 'year', 'month', 'day', 'hour', 'lineID', 'temp', 'humidity', 'precip', 'windspeed']].values\n",
    "y_salida = resultado_hora['salida'].values\n",
    "y_entrada = resultado_hora['entrada'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_salida_train, y_salida_test, y_entrada_train, y_entrada_test = train_test_split(X, y_salida, y_entrada, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_salida = xgb.XGBRegressor(n_estimators = 300, learning_rate = 0.1, max_depth = 12, random_state=42)\n",
    "# Realizar predicciones para la variable \"salida\"\n",
    "xgb_salida.fit(X_train, y_salida_train)\n",
    "y_salida_pred = xgb_salida.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"salida\"\n",
    "rmse_salida = np.sqrt(mean_squared_error(y_salida_test, y_salida_pred))\n",
    "r2_salida = r2_score(y_salida_test, y_salida_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'salida': {rmse_salida}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'salida': {r2_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_entrada = xgb.XGBRegressor(n_estimators = 300, learning_rate = 0.1, max_depth = 12, random_state=42)\n",
    "# Realizar predicciones para la variable \"entrada\"\n",
    "xgb_entrada.fit(X_train, y_entrada_train)\n",
    "y_entrada_pred = xgb_entrada.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo para la variable \"entrada\"\n",
    "rmse_entrada = np.sqrt(mean_squared_error(y_entrada_test, y_entrada_pred))\n",
    "r2_entrada = r2_score(y_entrada_test, y_entrada_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) para la variable 'entrada': {rmse_entrada}\")\n",
    "print(f\"Coeficiente de determinación (R^2) para la variable 'entrada': {r2_entrada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la variable \"entrada\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.title('Predicciones vs. Valores Reales (Entrada)')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
